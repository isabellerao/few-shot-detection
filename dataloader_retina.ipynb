{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import skimage.color\n",
    "import skimage\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class CocoDataset(Dataset):\n",
    "    \"\"\"Coco dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, set_name='train2017', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): COCO directory.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.set_name = set_name\n",
    "        self.transform = transform\n",
    "\n",
    "        self.coco      = COCO(os.path.join(self.root_dir, 'annotations', 'instances_' + self.set_name + '.json'))\n",
    "        self.image_ids = self.coco.getImgIds()\n",
    "\n",
    "        self.load_classes()\n",
    "\n",
    "    def load_classes(self):\n",
    "        # load class names (name -> label)\n",
    "        categories = self.coco.loadCats(self.coco.getCatIds())\n",
    "        categories.sort(key=lambda x: x['id'])\n",
    "\n",
    "        self.classes             = {}\n",
    "        self.coco_labels         = {}\n",
    "        self.coco_labels_inverse = {}\n",
    "        for c in categories:\n",
    "            self.coco_labels[len(self.classes)] = c['id']\n",
    "            self.coco_labels_inverse[c['id']] = len(self.classes)\n",
    "            self.classes[c['name']] = len(self.classes)\n",
    "\n",
    "        # also load the reverse (label -> name)\n",
    "        self.labels = {}\n",
    "        for key, value in self.classes.items():\n",
    "            self.labels[value] = key\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img = self.load_image(idx)\n",
    "        annot = self.load_annotations(idx)\n",
    "        sample = {'img': img, 'annot': annot}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def load_image(self, image_index):\n",
    "        image_info = self.coco.loadImgs(self.image_ids[image_index])[0]\n",
    "        path       = os.path.join(self.root_dir, 'images', self.set_name, image_info['file_name'])\n",
    "        img = skimage.io.imread(path)\n",
    "\n",
    "        if len(img.shape) == 2:\n",
    "            img = skimage.color.gray2rgb(img)\n",
    "\n",
    "        return img.astype(np.float32)/255.0\n",
    "\n",
    "    def load_annotations(self, image_index):\n",
    "        # get ground truth annotations\n",
    "        annotations_ids = self.coco.getAnnIds(imgIds=self.image_ids[image_index], iscrowd=False)\n",
    "        annotations     = np.zeros((0, 5))\n",
    "\n",
    "        # some images appear to miss annotations (like image with id 257034)\n",
    "        if len(annotations_ids) == 0:\n",
    "            return annotations\n",
    "\n",
    "        # parse annotations\n",
    "        coco_annotations = self.coco.loadAnns(annotations_ids)\n",
    "        for idx, a in enumerate(coco_annotations):\n",
    "\n",
    "            # some annotations have basically no width / height, skip them\n",
    "            if a['bbox'][2] < 1 or a['bbox'][3] < 1:\n",
    "                continue\n",
    "\n",
    "            annotation        = np.zeros((1, 5))\n",
    "            annotation[0, :4] = a['bbox']\n",
    "            annotation[0, 4]  = self.coco_label_to_label(a['category_id'])\n",
    "            annotations       = np.append(annotations, annotation, axis=0)\n",
    "\n",
    "        # transform from [x, y, w, h] to [x1, y1, x2, y2]\n",
    "        annotations[:, 2] = annotations[:, 0] + annotations[:, 2]\n",
    "        annotations[:, 3] = annotations[:, 1] + annotations[:, 3]\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def coco_label_to_label(self, coco_label):\n",
    "        return self.coco_labels_inverse[coco_label]\n",
    "\n",
    "\n",
    "    def label_to_coco_label(self, label):\n",
    "        return self.coco_labels[label]\n",
    "\n",
    "    def image_aspect_ratio(self, image_index):\n",
    "        image = self.coco.loadImgs(self.image_ids[image_index])[0]\n",
    "        return float(image['width']) / float(image['height'])\n",
    "\n",
    "    def num_classes(self):\n",
    "        return 80\n",
    "\n",
    "\n",
    "\n",
    "def collater(data):\n",
    "\n",
    "    imgs = [s['img'] for s in data]\n",
    "    annots = [s['annot'] for s in data]\n",
    "    scales = [s['scale'] for s in data]\n",
    "        \n",
    "    widths = [int(s.shape[0]) for s in imgs]\n",
    "    heights = [int(s.shape[1]) for s in imgs]\n",
    "    batch_size = len(imgs)\n",
    "\n",
    "    max_width = np.array(widths).max()\n",
    "    max_height = np.array(heights).max()\n",
    "\n",
    "    padded_imgs = torch.zeros(batch_size, max_width, max_height, 3)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        img = imgs[i]\n",
    "        padded_imgs[i, :int(img.shape[0]), :int(img.shape[1]), :] = img\n",
    "\n",
    "    max_num_annots = max(annot.shape[0] for annot in annots)\n",
    "    \n",
    "    if max_num_annots > 0:\n",
    "\n",
    "        annot_padded = torch.ones((len(annots), max_num_annots, 5)) * -1\n",
    "\n",
    "        if max_num_annots > 0:\n",
    "            for idx, annot in enumerate(annots):\n",
    "                #print(annot.shape)\n",
    "                if annot.shape[0] > 0:\n",
    "                    annot_padded[idx, :annot.shape[0], :] = annot\n",
    "    else:\n",
    "        annot_padded = torch.ones((len(annots), 1, 5)) * -1\n",
    "\n",
    "\n",
    "    padded_imgs = padded_imgs.permute(0, 3, 1, 2)\n",
    "\n",
    "    return {'img': padded_imgs, 'annot': annot_padded, 'scale': scales}\n",
    "\n",
    "class Resizer(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample, min_side=608, max_side=1024):\n",
    "        image, annots = sample['img'], sample['annot']\n",
    "\n",
    "        rows, cols, cns = image.shape\n",
    "\n",
    "        smallest_side = min(rows, cols)\n",
    "\n",
    "        # rescale the image so the smallest side is min_side\n",
    "        scale = min_side / smallest_side\n",
    "\n",
    "        # check if the largest side is now greater than max_side, which can happen\n",
    "        # when images have a large aspect ratio\n",
    "        largest_side = max(rows, cols)\n",
    "\n",
    "        if largest_side * scale > max_side:\n",
    "            scale = max_side / largest_side\n",
    "\n",
    "        # resize the image with the computed scale\n",
    "        image = skimage.transform.resize(image, (int(round(rows*scale)), int(round((cols*scale)))))\n",
    "        rows, cols, cns = image.shape\n",
    "\n",
    "        pad_w = 32 - rows%32\n",
    "        pad_h = 32 - cols%32\n",
    "\n",
    "        new_image = np.zeros((rows + pad_w, cols + pad_h, cns)).astype(np.float32)\n",
    "        new_image[:rows, :cols, :] = image.astype(np.float32)\n",
    "\n",
    "        annots[:, :4] *= scale\n",
    "\n",
    "        return {'img': torch.from_numpy(new_image), 'annot': torch.from_numpy(annots), 'scale': scale}\n",
    "\n",
    "\n",
    "class Augmenter(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample, flip_x=0.5):\n",
    "\n",
    "        if np.random.rand() < flip_x:\n",
    "            image, annots = sample['img'], sample['annot']\n",
    "            image = image[:, ::-1, :]\n",
    "\n",
    "            rows, cols, channels = image.shape\n",
    "\n",
    "            x1 = annots[:, 0].copy()\n",
    "            x2 = annots[:, 2].copy()\n",
    "            \n",
    "            x_tmp = x1.copy()\n",
    "\n",
    "            annots[:, 0] = cols - x2\n",
    "            annots[:, 2] = cols - x_tmp\n",
    "\n",
    "            sample = {'img': image, 'annot': annots}\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Normalizer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mean = np.array([[[0.485, 0.456, 0.406]]])\n",
    "        self.std = np.array([[[0.229, 0.224, 0.225]]])\n",
    "\n",
    "    def __call__(self, sample):\n",
    "\n",
    "        image, annots = sample['img'], sample['annot']\n",
    "\n",
    "        return {'img':((image.astype(np.float32)-self.mean)/self.std), 'annot': annots}\n",
    "\n",
    "class UnNormalizer(object):\n",
    "    def __init__(self, mean=None, std=None):\n",
    "        if mean == None:\n",
    "            self.mean = [0.485, 0.456, 0.406]\n",
    "        else:\n",
    "            self.mean = mean\n",
    "        if std == None:\n",
    "            self.std = [0.229, 0.224, 0.225]\n",
    "        else:\n",
    "            self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class AspectRatioBasedSampler(Sampler):\n",
    "\n",
    "    def __init__(self, data_source, batch_size, drop_last):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        self.groups = self.group_images()\n",
    "\n",
    "    def __iter__(self):\n",
    "        random.shuffle(self.groups)\n",
    "        for group in self.groups:\n",
    "            yield group\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return len(self.data_source) // self.batch_size\n",
    "        else:\n",
    "            return (len(self.data_source) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def group_images(self):\n",
    "        # determine the order of the images\n",
    "        order = list(range(len(self.data_source)))\n",
    "        order.sort(key=lambda x: self.data_source.image_aspect_ratio(x))\n",
    "\n",
    "        # divide into groups, one group = one batch\n",
    "        return [[order[x % len(order)] for x in range(i, i + self.batch_size)] for i in range(0, len(order), self.batch_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.14s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_path = '/scratch/users/isarao/coco'\n",
    "\n",
    "dataset_val = CocoDataset(coco_path, set_name='val2017', transform=transforms.Compose([Normalizer(), Resizer()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/users/isarao/coco\n",
      "val2017\n",
      "Compose(\n",
      "    <__main__.Normalizer object at 0x7f17e814b208>\n",
      "    <__main__.Resizer object at 0x7f17e814b630>\n",
      ")\n",
      "<pycocotools.coco.COCO object at 0x7f17e814b470>\n"
     ]
    }
   ],
   "source": [
    "# access the object attributes\n",
    "print(dataset_val.root_dir)\n",
    "print(dataset_val.set_name)\n",
    "print(dataset_val.transform) \n",
    "print(dataset_val.coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'supercategory': 'person', 'id': 1, 'name': 'person'}, {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'}, {'supercategory': 'vehicle', 'id': 3, 'name': 'car'}, {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'}, {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'}, {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'}, {'supercategory': 'vehicle', 'id': 7, 'name': 'train'}, {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'}, {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'}, {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'}, {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'}, {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'}, {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'}, {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'}, {'supercategory': 'animal', 'id': 16, 'name': 'bird'}, {'supercategory': 'animal', 'id': 17, 'name': 'cat'}, {'supercategory': 'animal', 'id': 18, 'name': 'dog'}, {'supercategory': 'animal', 'id': 19, 'name': 'horse'}, {'supercategory': 'animal', 'id': 20, 'name': 'sheep'}, {'supercategory': 'animal', 'id': 21, 'name': 'cow'}, {'supercategory': 'animal', 'id': 22, 'name': 'elephant'}, {'supercategory': 'animal', 'id': 23, 'name': 'bear'}, {'supercategory': 'animal', 'id': 24, 'name': 'zebra'}, {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'}, {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'}, {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'}, {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'}, {'supercategory': 'accessory', 'id': 32, 'name': 'tie'}, {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'}, {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'}, {'supercategory': 'sports', 'id': 35, 'name': 'skis'}, {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'}, {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'}, {'supercategory': 'sports', 'id': 38, 'name': 'kite'}, {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'}, {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'}, {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'}, {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'}, {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'}, {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'}, {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'}, {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'}, {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'}, {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'}, {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'}, {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'}, {'supercategory': 'food', 'id': 52, 'name': 'banana'}, {'supercategory': 'food', 'id': 53, 'name': 'apple'}, {'supercategory': 'food', 'id': 54, 'name': 'sandwich'}, {'supercategory': 'food', 'id': 55, 'name': 'orange'}, {'supercategory': 'food', 'id': 56, 'name': 'broccoli'}, {'supercategory': 'food', 'id': 57, 'name': 'carrot'}, {'supercategory': 'food', 'id': 58, 'name': 'hot dog'}, {'supercategory': 'food', 'id': 59, 'name': 'pizza'}, {'supercategory': 'food', 'id': 60, 'name': 'donut'}, {'supercategory': 'food', 'id': 61, 'name': 'cake'}, {'supercategory': 'furniture', 'id': 62, 'name': 'chair'}, {'supercategory': 'furniture', 'id': 63, 'name': 'couch'}, {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'}, {'supercategory': 'furniture', 'id': 65, 'name': 'bed'}, {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'}, {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'}, {'supercategory': 'electronic', 'id': 72, 'name': 'tv'}, {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'}, {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'}, {'supercategory': 'electronic', 'id': 75, 'name': 'remote'}, {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'}, {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'}, {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'}, {'supercategory': 'appliance', 'id': 79, 'name': 'oven'}, {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'}, {'supercategory': 'appliance', 'id': 81, 'name': 'sink'}, {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'}, {'supercategory': 'indoor', 'id': 84, 'name': 'book'}, {'supercategory': 'indoor', 'id': 85, 'name': 'clock'}, {'supercategory': 'indoor', 'id': 86, 'name': 'vase'}, {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'}, {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'}, {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'}, {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}]\n"
     ]
    }
   ],
   "source": [
    "categories = dataset_val.coco.loadCats(dataset_val.coco.getCatIds())\n",
    "categories.sort(key=lambda x: x['id'])\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'person': 0, 'bicycle': 1, 'car': 2, 'motorcycle': 3, 'airplane': 4, 'bus': 5, 'train': 6, 'truck': 7, 'boat': 8, 'traffic light': 9, 'fire hydrant': 10, 'stop sign': 11, 'parking meter': 12, 'bench': 13, 'bird': 14, 'cat': 15, 'dog': 16, 'horse': 17, 'sheep': 18, 'cow': 19, 'elephant': 20, 'bear': 21, 'zebra': 22, 'giraffe': 23, 'backpack': 24, 'umbrella': 25, 'handbag': 26, 'tie': 27, 'suitcase': 28, 'frisbee': 29, 'skis': 30, 'snowboard': 31, 'sports ball': 32, 'kite': 33, 'baseball bat': 34, 'baseball glove': 35, 'skateboard': 36, 'surfboard': 37, 'tennis racket': 38, 'bottle': 39, 'wine glass': 40, 'cup': 41, 'fork': 42, 'knife': 43, 'spoon': 44, 'bowl': 45, 'banana': 46, 'apple': 47, 'sandwich': 48, 'orange': 49, 'broccoli': 50, 'carrot': 51, 'hot dog': 52, 'pizza': 53, 'donut': 54, 'cake': 55, 'chair': 56, 'couch': 57, 'potted plant': 58, 'bed': 59, 'dining table': 60, 'toilet': 61, 'tv': 62, 'laptop': 63, 'mouse': 64, 'remote': 65, 'keyboard': 66, 'cell phone': 67, 'microwave': 68, 'oven': 69, 'toaster': 70, 'sink': 71, 'refrigerator': 72, 'book': 73, 'clock': 74, 'vase': 75, 'scissors': 76, 'teddy bear': 77, 'hair drier': 78, 'toothbrush': 79}\n",
      "{0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 13, 12: 14, 13: 15, 14: 16, 15: 17, 16: 18, 17: 19, 18: 20, 19: 21, 20: 22, 21: 23, 22: 24, 23: 25, 24: 27, 25: 28, 26: 31, 27: 32, 28: 33, 29: 34, 30: 35, 31: 36, 32: 37, 33: 38, 34: 39, 35: 40, 36: 41, 37: 42, 38: 43, 39: 44, 40: 46, 41: 47, 42: 48, 43: 49, 44: 50, 45: 51, 46: 52, 47: 53, 48: 54, 49: 55, 50: 56, 51: 57, 52: 58, 53: 59, 54: 60, 55: 61, 56: 62, 57: 63, 58: 64, 59: 65, 60: 67, 61: 70, 62: 72, 63: 73, 64: 74, 65: 75, 66: 76, 67: 77, 68: 78, 69: 79, 70: 80, 71: 81, 72: 82, 73: 84, 74: 85, 75: 86, 76: 87, 77: 88, 78: 89, 79: 90}\n",
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 13: 11, 14: 12, 15: 13, 16: 14, 17: 15, 18: 16, 19: 17, 20: 18, 21: 19, 22: 20, 23: 21, 24: 22, 25: 23, 27: 24, 28: 25, 31: 26, 32: 27, 33: 28, 34: 29, 35: 30, 36: 31, 37: 32, 38: 33, 39: 34, 40: 35, 41: 36, 42: 37, 43: 38, 44: 39, 46: 40, 47: 41, 48: 42, 49: 43, 50: 44, 51: 45, 52: 46, 53: 47, 54: 48, 55: 49, 56: 50, 57: 51, 58: 52, 59: 53, 60: 54, 61: 55, 62: 56, 63: 57, 64: 58, 65: 59, 67: 60, 70: 61, 72: 62, 73: 63, 74: 64, 75: 65, 76: 66, 77: 67, 78: 68, 79: 69, 80: 70, 81: 71, 82: 72, 84: 73, 85: 74, 86: 75, 87: 76, 88: 77, 89: 78, 90: 79}\n",
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_val.classes)\n",
    "print(dataset_val.coco_labels)\n",
    "print(dataset_val.coco_labels_inverse)\n",
    "print(dataset_val.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[270.9301, 313.1729, 291.8136, 358.9315,  58.0000],\n",
      "        [ 70.0522, 569.0087, 232.6261, 607.3391,  56.0000],\n",
      "        [307.9652, 501.1242, 440.1391, 568.5329,  56.0000],\n",
      "        [210.2887, 470.6713, 761.0838, 599.4087,  60.0000],\n",
      "        [797.9075, 198.1023, 929.0769, 598.4306,  72.0000],\n",
      "        [583.2835, 472.9976, 683.3127, 546.7770,  46.0000],\n",
      "        [363.3990, 328.0821, 522.4835, 515.8219,  69.0000],\n",
      "        [704.0376, 355.5214, 777.7113, 364.6943,  71.0000],\n",
      "        [570.3833, 488.7791, 616.0097, 530.9955,  49.0000],\n",
      "        [612.2296, 531.2334, 656.3492, 573.3440,  49.0000],\n",
      "        [609.4539, 471.2000, 640.4619, 500.2254,  49.0000],\n",
      "        [542.4153, 494.3569, 582.0410, 550.3986,  49.0000],\n",
      "        [639.5896, 476.9363, 775.3850, 596.9503,  56.0000],\n",
      "        [575.9875, 530.1760, 613.3663, 565.8365,  49.0000]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([14, 5])\n"
     ]
    }
   ],
   "source": [
    "# Call the __getitem__ method\n",
    "sample = dataset_val.__getitem__(1)\n",
    "sample['img']\n",
    "print(sample['annot'])\n",
    "print(sample['annot'].shape)\n",
    "# this image has 14 bounding boxes\n",
    "# the coordinates are the indexes 0 - 3, and the 4th is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(dataset_val.coco_label_to_label(13))\n",
    "print(dataset_val.label_to_coco_label(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=1, drop_last=False)\n",
    "dataloader_val = DataLoader(dataset_val, num_workers=3, collate_fn=collater, batch_sampler=sampler_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'img': tensor([[[[-0.5491, -0.5215, -0.5055,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.5215, -0.5053, -0.4909,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.5128, -0.4935, -0.4710,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.1063, -0.0961, -0.1146,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.0961, -0.0860, -0.0996,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.0998, -0.0944, -0.1002,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.2456,  0.2849,  0.2907,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.2647,  0.2981,  0.3056,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.2651,  0.2858,  0.3045,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]]), 'annot': tensor([[[426.4993, 269.0400, 525.7047, 317.2113,  37.0000],\n",
      "         [415.2767, 196.1813, 524.3747, 296.7167,   0.0000]]]), 'scale': [1.2666666666666666]}\n",
      "1\n",
      "{'img': tensor([[[[-1.0984, -1.0249, -0.8877,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.1428, -1.0581, -0.9227,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.2018, -1.1083, -0.9822,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.3286, -0.2616, -0.1476,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.3679, -0.2923, -0.1816,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.4140, -0.3362, -0.2404,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.7295,  0.7810,  0.8586,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.7457,  0.8029,  0.8705,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.7654,  0.8217,  0.8680,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]]), 'annot': tensor([[[163.9607,  47.8141, 255.5024, 169.4141,  56.0000],\n",
      "         [237.9886, 469.0143, 340.6651, 607.8861,  38.0000],\n",
      "         [250.5900,  49.9785, 676.4747, 600.4677,   0.0000],\n",
      "         [538.5712,  41.9620, 584.4774, 110.6218,   0.0000],\n",
      "         [613.7952,  22.9673, 668.5864,  94.9306,   0.0000],\n",
      "         [353.1953,  50.4911, 409.2111,  98.2340,   0.0000],\n",
      "         [  0.0000,  65.2710,  72.5898, 197.7780,   0.0000],\n",
      "         [383.9228,  77.8724, 454.9748, 150.2913,   0.0000],\n",
      "         [267.1925,  10.9070, 333.9871, 218.1111,   0.0000],\n",
      "         [393.9043,  37.5906, 428.5901,  91.9404,   0.0000],\n",
      "         [304.1851,   0.0000, 358.6773, 104.9120,   0.0000],\n",
      "         [370.2108,   0.0000, 429.4160,  58.6499,   0.0000],\n",
      "         [838.6982,  33.0769, 911.2881, 114.9220,   0.0000],\n",
      "         [826.1965, 111.9033, 910.1917, 296.0262,   0.0000],\n",
      "         [514.1231,  23.2094, 578.1981,  38.4877,  56.0000]]]), 'scale': [1.423887587822014]}\n",
      "2\n",
      "{'img': tensor([[[[-0.5939, -0.5766, -0.5601,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.6274, -0.5933, -0.5425,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.5770, -0.5939, -0.5770,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-1.9833, -1.9661, -2.0012,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-2.0176, -1.9832, -1.9833,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.9660, -1.9838, -2.0185,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-1.7348, -1.7175, -1.7355,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.7690, -1.7346, -1.7174,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.7176, -1.7352, -1.7524,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]]), 'annot': tensor([[[0.0000e+00, 2.3846e+02, 5.4075e+02, 4.1552e+02, 4.6000e+01],\n",
      "         [1.8384e+02, 1.7637e+02, 3.5240e+02, 2.5750e+02, 4.6000e+01],\n",
      "         [1.1340e+02, 1.1981e+02, 5.3696e+02, 2.5235e+02, 4.6000e+01],\n",
      "         [1.3571e+02, 6.6801e+01, 5.4591e+02, 1.7468e+02, 4.6000e+01],\n",
      "         [4.3772e+02, 2.2376e+02, 5.2880e+02, 3.2826e+02, 4.6000e+01],\n",
      "         [0.0000e+00, 3.9739e-01, 6.0800e+02, 5.2197e+01, 6.0000e+01]]]), 'scale': [0.9934640522875817]}\n",
      "3\n",
      "{'img': tensor([[[[2.2430, 2.2397, 2.2311,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.2397, 2.2374, 2.2311,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.2318, 2.2318, 2.2311,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[2.4111, 2.4111, 2.4118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.4111, 2.4111, 2.4118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.4111, 2.4111, 2.4118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6393,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.6400, 2.6400, 2.6393,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.6393, 2.6393, 2.6386,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]), 'annot': tensor([[[321.5428, 147.8170, 685.7429, 441.5863,   1.0000],\n",
      "         [  0.0000, 111.5964, 221.8308, 568.9745,   3.0000],\n",
      "         [  0.0000,   6.1611, 121.8756, 196.5056,   0.0000],\n",
      "         [676.3068,   2.4969, 810.6667, 512.1306,   0.0000],\n",
      "         [143.1313,  95.5776, 323.0831, 373.6849,   1.0000]]]), 'scale': [1.6213333333333333]}\n",
      "4\n",
      "{'img': tensor([[[[-0.0542,  0.1126,  0.2482,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0037,  0.1075,  0.2742,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.1032,  0.1444,  0.2666,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.9522, -0.8008, -0.6802,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.9325, -0.8397, -0.6792,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.8846, -0.8478, -0.7219,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-1.5715, -1.4410, -1.3623,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.5821, -1.5100, -1.3773,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.5575, -1.5315, -1.4319,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]]), 'annot': tensor([[[535.5847, 271.3200, 559.6513, 368.3213,  39.0000],\n",
      "         [601.9580, 288.7240, 615.4100, 310.4093,  39.0000],\n",
      "         [428.8300, 347.1553, 810.6667, 606.9993,  60.0000],\n",
      "         [  1.3680,  21.8627, 520.5620, 601.1727,   0.0000],\n",
      "         [561.0573, 304.2027, 635.7400, 420.6220,  41.0000],\n",
      "         [566.0607, 552.8113, 728.2067, 607.6960,  42.0000],\n",
      "         [567.0486, 287.1787, 582.3627, 309.2947,  39.0000],\n",
      "         [529.0993, 560.2340, 745.3700, 607.6580,  43.0000]]]), 'scale': [1.2666666666666666]}\n",
      "5\n",
      "{'img': tensor([[[[-1.9047, -1.9047, -1.9047,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.9012, -1.9012, -1.9012,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.8824, -1.8824, -1.8824,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-1.2090, -1.2090, -1.2090,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.2072, -1.2072, -1.2072,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.1975, -1.1975, -1.1975,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.4933, -0.4933, -0.4933,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.4916, -0.4916, -0.4916,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.4820, -0.4820, -0.4820,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]]), 'annot': tensor([[[175.6666, 209.6420, 411.7340, 511.5912,   0.0000],\n",
      "         [344.1099, 236.2851, 426.3804, 469.4305,   0.0000],\n",
      "         [487.7612, 197.8813, 627.1293, 467.0529,   0.0000],\n",
      "         [792.1968, 168.5884, 907.4627, 482.0079,   0.0000],\n",
      "         [466.8532, 288.0468, 545.2943, 314.9077,  29.0000],\n",
      "         [439.9379, 334.5815, 501.4276, 441.1539,   0.0000],\n",
      "         [765.8622, 393.6936, 799.8739, 405.8536,  29.0000]]]), 'scale': [1.8149253731343284]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "{'img': tensor([[[[2.2415, 2.2358, 2.2292,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.2290, 2.2260, 2.2224,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.2182, 2.2166, 2.2147,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[2.3657, 2.3774, 2.3909,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.3705, 2.3768, 2.3840,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.3797, 2.3780, 2.3761,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[2.0975, 2.1054, 2.1145,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.0847, 2.0954, 2.1076,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.0724, 2.0812, 2.0912,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]), 'annot': tensor([[[ 41.8000,  30.7298, 593.2015, 707.5170,   0.0000],\n",
      "         [250.7283, 383.9434, 384.8898, 512.6558,  54.0000]]]), 'scale': [1.4339622641509433]}\n",
      "7\n",
      "{'img': tensor([[[[-1.6829, -1.6751, -1.6798,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.6553, -1.6590, -1.6746,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.6619, -1.6578, -1.6679,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-1.6419, -1.6249, -1.6330,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.6147, -1.6153, -1.6378,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.5925, -1.6074, -1.6404,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-1.5184, -1.5646, -1.6458,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.5242, -1.5471, -1.6060,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.5552, -1.5366, -1.5444,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]]), 'annot': tensor([[[162.5640, 101.8780, 463.8533, 697.9587,  61.0000]]]), 'scale': [1.2666666666666666]}\n",
      "8\n",
      "{'img': tensor([[[[0.8888, 0.8539, 0.8787,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7844, 0.7208, 0.7487,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5542, 0.5922, 0.6898,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.2246, 1.2768, 1.3319,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [1.1856, 1.1910, 1.2300,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [1.0291, 1.0856, 1.1500,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.1510, 1.2353, 1.3357,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [1.2858, 1.2243, 1.2258,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9379, 1.0212, 1.1579,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]), 'annot': tensor([[[3.9359e+02, 6.2333e+01, 4.9387e+02, 4.0022e+02, 0.0000e+00],\n",
      "         [5.3048e+01, 7.6304e+01, 3.8901e+02, 5.9997e+02, 0.0000e+00],\n",
      "         [7.0485e+02, 8.8540e+01, 7.1014e+02, 1.0160e+02, 0.0000e+00],\n",
      "         [7.1536e+02, 8.5234e+01, 7.2700e+02, 1.2017e+02, 0.0000e+00],\n",
      "         [6.7558e+02, 8.4284e+01, 6.8548e+02, 1.0375e+02, 0.0000e+00],\n",
      "         [3.4548e+02, 1.2375e+01, 6.8281e+02, 4.3131e+02, 7.2000e+01],\n",
      "         [5.0667e-02, 3.9037e+02, 3.6442e+01, 4.4013e+02, 4.1000e+01],\n",
      "         [3.8190e+01, 3.4899e+02, 7.7115e+01, 4.1478e+02, 4.1000e+01],\n",
      "         [7.3596e+02, 8.7020e+01, 7.4374e+02, 1.1446e+02, 0.0000e+00],\n",
      "         [7.9387e+02, 8.8059e+01, 8.0317e+02, 1.1879e+02, 0.0000e+00],\n",
      "         [7.4906e+02, 8.8173e+01, 7.6280e+02, 1.0996e+02, 0.0000e+00],\n",
      "         [7.8410e+02, 1.1309e+02, 8.0998e+02, 3.9995e+02, 0.0000e+00],\n",
      "         [7.2798e+02, 8.5285e+01, 7.3615e+02, 1.1586e+02, 0.0000e+00],\n",
      "         [6.9833e+02, 8.4208e+01, 7.0689e+02, 9.5025e+01, 0.0000e+00],\n",
      "         [0.0000e+00, 4.0093e+02, 2.9108e+01, 4.5454e+02, 4.1000e+01],\n",
      "         [3.6776e+02, 2.1157e+02, 3.8793e+02, 2.4439e+02, 4.1000e+01],\n",
      "         [6.8530e+02, 8.4018e+01, 6.9612e+02, 1.0055e+02, 0.0000e+00],\n",
      "         [7.6199e+02, 9.1605e+01, 7.7091e+02, 1.0043e+02, 0.0000e+00]]]), 'scale': [1.2666666666666666]}\n",
      "9\n",
      "{'img': tensor([[[[-1.2959, -1.2959, -1.2878,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.2959, -1.2959, -1.2878,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.2951, -1.2904, -1.2835,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.3901, -0.3901, -0.3818,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.3901, -0.3901, -0.3818,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.3892, -0.3844, -0.3774,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.8797,  0.8797,  0.8879,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.8797,  0.8797,  0.8879,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.8805,  0.8853,  0.8922,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]]), 'annot': tensor([[[269.1033, 352.8427, 399.9373, 584.3766,   9.0000]]]), 'scale': [1.2666666666666666]}\n"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(dataloader_val):\n",
    "    if idx < 10: \n",
    "        print(idx)\n",
    "        print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "negative step not yet supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-620aa05f8066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: negative step not yet supported"
     ]
    }
   ],
   "source": [
    "image, annots = sample['img'], sample['annot']\n",
    "image = image[:, ::-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
